{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638eaa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Dropout, Flatten\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685cddba",
   "metadata": {},
   "source": [
    "# Feed the images to the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8011edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb29db05",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self):\n",
    "        # Use VGG-16 as the architecture and ImageNet for the weight\n",
    "        base_model = VGG16(weights='imagenet')\n",
    "        # Customize the model to return features from fully-connected layer\n",
    "        self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "    def extract(self, img):\n",
    "        # Resize the image\n",
    "        img = img.resize((224, 224))\n",
    "        # Convert the image color space\n",
    "        img = img.convert('RGB')\n",
    "        # Reformat the image\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        # Extract Features\n",
    "        feature = self.model.predict(x)[0]\n",
    "        return feature / np.linalg.norm(feature)\n",
    "\n",
    "    \n",
    "    \n",
    "# Iterate through images (Change the path based on your image location)\n",
    "for img_path in sorted(\"<IMAGE DATABASE PATH LIST HERE>\"):\n",
    "    print(img_path)\n",
    "    # Extract Features\n",
    "    feature = fe.extract(img=Image.open(img_path))\n",
    "    # Save the Numpy array (.npy) on designated path\n",
    "    feature_path = \"<IMAGE FEATURE PATH HERE>.npy\"\n",
    "    np.save(feature_path, feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
